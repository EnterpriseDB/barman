.\" Automatically generated by Pandoc 2.2.1
.\"
.TH "BARMAN\-CLOUD\-BACKUP" "1" "September 22, 2020" "Barman User manuals" "Version 2.14"
.hy
.SH NAME
.PP
barman\-cloud\-backup \- Backup a PostgreSQL instance and stores it in
the Cloud
.SH SYNOPSIS
.PP
barman\-cloud\-backup [\f[I]OPTIONS\f[]] \f[I]DESTINATION_URL\f[]
\f[I]SERVER_NAME\f[]
.SH DESCRIPTION
.PP
This script can be used to perform a backup of a local PostgreSQL
instance and ship the resulting tarball(s) to the Cloud.
Currently AWS S3 and Azure Blob Storage are supported.
.PP
It requires read access to PGDATA and tablespaces (normally run as
\f[C]postgres\f[] user).
It can also be used as a hook script on a barman server, in which case
it requires read access to the directory where barman backups are
stored.
.PP
This script and Barman are administration tools for disaster recovery of
PostgreSQL servers written in Python and maintained by EnterpriseDB.
.PP
\f[B]IMPORTANT:\f[] the Cloud upload process may fail if any file with a
size greater than the configured \f[C]\-\-max\-archive\-size\f[] is
present either in the data directory or in any tablespaces.
However, PostgreSQL creates files with a maximum size of 1GB, and that
size is always allowed, regardless of the \f[C]max\-archive\-size\f[]
parameter.
.SH POSITIONAL ARGUMENTS
.TP
.B DESTINATION_URL
URL of the cloud destination, such as a bucket in AWS S3.
For example: \f[C]s3://BUCKET_NAME/path/to/folder\f[] (where
\f[C]BUCKET_NAME\f[] is the bucket you have created in AWS).
.RS
.RE
.TP
.B SERVER_NAME
the name of the server as configured in Barman.
.RS
.RE
.SH OPTIONS
.TP
.B \-h, \[en]help
show a help message and exit
.RS
.RE
.TP
.B \-V, \[en]version
show program's version number and exit
.RS
.RE
.TP
.B \-v, \[en]verbose
increase output verbosity (e.g., \-vv is more than \-v)
.RS
.RE
.TP
.B \-q, \[en]quiet
decrease output verbosity (e.g., \-qq is less than \-q)
.RS
.RE
.TP
.B \-t, \[en]test
test connectivity to the cloud destination and exit
.RS
.RE
.TP
.B \-z, \[en]gzip
gzip\-compress the tar files when uploading to the cloud
.RS
.RE
.TP
.B \-j, \[en]bzip2
bzip2\-compress the tar files when uploading to the cloud
.RS
.RE
.TP
.B \-d, \[en]dbname
database name or conninfo string for Postgres connection (default:
postgres)
.RS
.RE
.TP
.B \-h, \[en]host
host or Unix socket for PostgreSQL connection (default: libpq settings)
.RS
.RE
.TP
.B \-p, \[en]port
port for PostgreSQL connection (default: libpq settings)
.RS
.RE
.TP
.B \-U, \[en]user
user name for PostgreSQL connection (default: libpq settings)
.RS
.RE
.TP
.B \[en]immediate\-checkpoint
forces the initial checkpoint to be done as quickly as possible
.RS
.RE
.TP
.B \-J JOBS, \[en]jobs JOBS
number of subprocesses to upload data to cloud storage (default: 2)
.RS
.RE
.TP
.B \-S MAX_ARCHIVE_SIZE, \[en]max\-archive\-size MAX_ARCHIVE_SIZE
maximum size of an archive when uploading to cloud storage (default:
100GB)
.RS
.RE
.TP
.B \[en]cloud\-provider {aws\-s3,azure\-blob\-storage}
the cloud provider to which the backup should be uploaded
.RS
.RE
.TP
.B \-P, \[en]profile
profile name (e.g.\ INI section in AWS credentials file)
.RS
.RE
.TP
.B \[en]endpoint\-url
override the default S3 URL construction mechanism by specifying an
endpoint
.RS
.RE
.TP
.B \-e, \[en]encryption
the encryption algorithm used when storing the uploaded data in S3
Allowed values: `AES256'|`aws:kms'
.RS
.RE
.TP
.B \[en]encryption\-scope
the name of an encryption scope defined in the Azure Blob Storage
service which is to be used to encrypt the data in Azure
.RS
.RE
.SH REFERENCES
.PP
For Boto:
.IP \[bu] 2
https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
.PP
For AWS:
.IP \[bu] 2
http://docs.aws.amazon.com/cli/latest/userguide/cli\-chap\-getting\-set\-up.html
.IP \[bu] 2
http://docs.aws.amazon.com/cli/latest/userguide/cli\-chap\-getting\-started.html.
.PP
For Azure Blob Storage:
.IP \[bu] 2
https://docs.microsoft.com/en\-us/azure/storage/blobs/authorize\-data\-operations\-cli#set\-environment\-variables\-for\-authorization\-parameters
.IP \[bu] 2
https://docs.microsoft.com/en\-us/python/api/azure\-storage\-blob/?view=azure\-python
.PP
For libpq settings information:
.IP \[bu] 2
https://www.postgresql.org/docs/current/libpq\-envars.html
.SH DEPENDENCIES
.PP
If using \f[C]\-\-cloud\-provider=aws\-s3\f[]:
.IP \[bu] 2
boto3
.PP
If using \f[C]\-\-cloud\-provider=azure\-blob\-storage\f[]:
.IP \[bu] 2
azure\-storage\-blob
.IP \[bu] 2
azure\-identity (optional, if you wish to use DefaultAzureCredential)
.SH EXIT STATUS
.TP
.B 0
Success
.RS
.RE
.TP
.B Not zero
Failure
.RS
.RE
.SH SEE ALSO
.PP
This script can be used in conjunction with \f[C]post_backup_script\f[]
or \f[C]post_backup_retry_script\f[] to relay barman backups to cloud
storage as follows:
.IP
.nf
\f[C]
post_backup_retry_script\ =\ \[aq]barman\-cloud\-backup\ [*OPTIONS*]\ *DESTINATION_URL*\ ${BARMAN_SERVER}\[aq]
\f[]
.fi
.PP
When running as a hook script, barman\-cloud\-backup will read the
location of the backup directory and the backup ID from BACKUP_DIR and
BACKUP_ID environment variables set by barman.
.SH BUGS
.PP
Barman has been extensively tested, and is currently being used in
several production environments.
However, we cannot exclude the presence of bugs.
.PP
Any bug can be reported via the Github issue tracker.
.SH RESOURCES
.IP \[bu] 2
Homepage: <http://www.pgbarman.org/>
.IP \[bu] 2
Documentation: <http://docs.pgbarman.org/>
.IP \[bu] 2
Professional support: <http://www.enterprisedb.com/>
.SH COPYING
.PP
Barman is the property of EnterpriseDB UK Limited and its code is
distributed under GNU General Public License v3.
.PP
Â© Copyright EnterpriseDB UK Limited 2011\-2021
.SH AUTHORS
EnterpriseDB <http://www.enterprisedb.com>.
